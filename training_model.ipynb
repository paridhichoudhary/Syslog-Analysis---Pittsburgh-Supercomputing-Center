{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv,re,os\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = '/pylon5/sy5fp1p/ehanna/logs/hosts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('(\\d+-\\d+-\\d+)T(\\d+:\\d+:\\d+)-(\\d+:\\d+)\\s(.*?)\\.pvt')\n",
    "timePattern = re.compile('.*T(\\d+:\\d+:\\d+)-\\d+:\\d+\\s.*\\.pvt.*')\n",
    "jobidpattern = re.compile('JID:(\\d+).*prolog started')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date: Date for which corpus has to be made\n",
    "# node: Node for which corpus has to be made\n",
    "# size: Size of the sliding window. How many minutes should it study?\n",
    "# slide: Shift in the sliding window\n",
    "# check: Number of seconds after the current time stamp for which to check if an nfs error occured\n",
    "def makeCorpus(date,node,size,slide,check):\n",
    "    direc = node +'.pvt.bridges.psc.edu'\n",
    "    fileName = date+'-'+direc+'.log'\n",
    "    with open(origin+direc+'/'+fileName) as file:\n",
    "        windowStarters = []\n",
    "        CorrespondingCorpuses = []\n",
    "        for line in file:\n",
    "            match = re.search(timePattern,line)\n",
    "            if match is not None:\n",
    "                currentTime = match.group(1)\n",
    "                if len(windowStarters)==0:\n",
    "                    windowStarters.append(currentTime)\n",
    "                    CorrespondingCorpuses.append([line,0])\n",
    "                    indexCheckStart = -1\n",
    "                else:\n",
    "                    i = len(windowStarters)-1\n",
    "                    while i>indexCheckStart:\n",
    "                        checkTime = windowStarters[i]\n",
    "                        FMT = '%H:%M:%S'\n",
    "                        tdelta = datetime.strptime(currentTime, FMT) - datetime.strptime(checkTime, FMT)\n",
    "                        sizeTimeRep = str(dt.timedelta(seconds=size))\n",
    "                        errorTimeCheck = size+check\n",
    "                        nextWindowStartTime = str(dt.timedelta(seconds=slide))\n",
    "                        errorTimeCheckRep = str(dt.timedelta(seconds=errorTimeCheck))\n",
    "                        if i==len(windowStarters)-1 and (str(tdelta)>=errorTimeCheckRep):\n",
    "                            windowStarters.append(currentTime)\n",
    "                            if 'not responding' not in line and 'nfs: server ' not in line:\n",
    "                                CorrespondingCorpuses.append([line,0])\n",
    "                            else:\n",
    "                                CorrespondingCorpuses.append(['',0])\n",
    "                            indexCheckStart +=1\n",
    "                            break\n",
    "                        elif (str(tdelta)<=sizeTimeRep):\n",
    "                            if 'not responding' not in line and 'nfs: server ' not in line:\n",
    "                                CorrespondingCorpuses[i][0]+= ' '+line\n",
    "                                if i==len(windowStarters)-1 and (str(tdelta)>=nextWindowStartTime):\n",
    "                                    windowStarters.append(currentTime)\n",
    "                                    line = re.sub(r'\\s\\d+\\s', ' ', line)\n",
    "                                    if 'not responding' not in line and 'nfs: server ' not in line:\n",
    "                                        CorrespondingCorpuses.append([line,0])\n",
    "                                    else:\n",
    "                                        CorrespondingCorpuses.append(['',0])\n",
    "                        elif (str(tdelta)<=errorTimeCheckRep):\n",
    "                            if 'not responding' in line and 'nfs: server ' in line:\n",
    "                                CorrespondingCorpuses[i][1]=1\n",
    "                        else:\n",
    "                            indexCheckStart +=1\n",
    "                            break\n",
    "                        i=i-1\n",
    "    windowStarters = [date+'_'+i+'_'+node for i in windowStarters]\n",
    "    return (CorrespondingCorpuses,windowStarters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "textCorpuseswithLabels = makeCorpus('2018-02-04','r150',120,60,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpusToBagOfWords(corpus,labels,index):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    columns = vectorizer.get_feature_names()\n",
    "    resultDF = pd.DataFrame(X.toarray(),columns=columns,index = index)\n",
    "    resultDF['Label'] = labels\n",
    "    return resultDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = corpusToBagOfWords(corpus,labels,textCorpuseswithLabels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<38>1 2018-02-02T23:56:00-05:00 r256.pvt.bridges.psc.edu systemd-logind - - -  New session of user monitor.\n"
     ]
    }
   ],
   "source": [
    "text = \"<38>1 2018-02-02T23:56:00-05:00 r256.pvt.bridges.psc.edu systemd-logind - - -  New session 4434 of user monitor.\"\n",
    "text = (re.sub(r'\\s\\d+\\s',' ',text))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCorpusDataFrame(dateRange, nodeMinimum,nodeMaximum):\n",
    "    startDate = datetime.strptime(dateRange.split(':')[0],\"%Y-%m-%d\")\n",
    "    endDate = datetime.strptime(dateRange.split(':')[1],\"%Y-%m-%d\")\n",
    "    currentDate = startDate\n",
    "    corpusMetaData = []\n",
    "    labelsMetaData = []\n",
    "    windowStarters = []\n",
    "    startTime = datetime.now()\n",
    "    while (currentDate<endDate):\n",
    "        count=0\n",
    "        for direc in os.listdir(origin):\n",
    "            if direc.startswith('r') and direc.endswith('.pvt.bridges.psc.edu'):\n",
    "                match = re.search(r'(r\\d+).pvt.bridges.psc.edu',direc)\n",
    "                if match is not None:\n",
    "                    node = match.group(1)\n",
    "                    if int(node.strip('r'))> nodeMinimum and int(node.strip('r'))< nodeMaximum:\n",
    "                        count+=1\n",
    "                        fileName = currentDate.strftime(\"%Y-%m-%d\")+'-'+direc+'.log'\n",
    "                        if fileName in os.listdir(origin+direc+'/'):\n",
    "                            with open(origin+direc+'/'+fileName) as file:\n",
    "                                textCorpuseswithLabels = makeCorpus(currentDate.strftime(\"%Y-%m-%d\"),node,300,120,60)\n",
    "                                # textStrings = text.split('\\n')\n",
    "                                for line in textCorpuseswithLabels[0]:\n",
    "                                    corpusMetaData.append(line[0])\n",
    "                                    labelsMetaData.append(line[1])\n",
    "                                for line in textCorpuseswithLabels[1]:\n",
    "                                    windowStarters.append(line)  \n",
    "        currentDate = currentDate+dt.timedelta(days=1)\n",
    "    endTime = datetime.now()\n",
    "    df = corpusToBagOfWords(corpusMetaData,labelsMetaData,windowStarters)\n",
    "    print(endTime-startTime)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "# Assumes the last column of data is the output dimension\n",
    "def get_pred_logreg(train,test):\n",
    "    # Your implementation goes here\n",
    "    # You may leverage the linear_model module from sklearn (scikit-learn)\n",
    "    # return (predicted output, actual output)\n",
    "    n, m = train.shape  # number of rows and columns\n",
    "    X_train = train.iloc[:,:m - 1]  # get training input data\n",
    "    # print(X_train)\n",
    "    Y_train = train.iloc[:,-1]\n",
    "    X_test = test.iloc[:, :m - 1]  # get test input data\n",
    "    Y_test = test.iloc[:,- 1]  # get test input data\n",
    "    lm = LogisticRegression().fit(X_train,Y_train)\n",
    "    pred = lm.predict(X_test)\n",
    "    return pd.DataFrame({'Prediction':pred,'Observed':Y_test},columns=['Prediction','Observed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your implementation of do_cv_class goes here\n",
    "def do_cv_class(df, num_folds, model_name):\n",
    "    Y = df.iloc[:,-1]\n",
    "    kf = KFold(n_splits=num_folds,shuffle=True,random_state=2)\n",
    "    predDF = pd.DataFrame(columns=['Prediction','Observed','Fold'])\n",
    "    count = 1\n",
    "    for train_index,test_index in kf.split(df):\n",
    "        if model_name==\"logreg\":\n",
    "            modelpredDF = get_pred_logreg(df.iloc[train_index],df.iloc[test_index])\n",
    "        elif model_name==\"svm\":\n",
    "            modelpredDF = get_pred_svm(df.iloc[train_index],df.iloc[test_index])\n",
    "        elif model_name==\"nb\":\n",
    "            modelpredDF = get_pred_nb(df.iloc[train_index],df.iloc[test_index])\n",
    "        elif model_name[-2:]==\"nn\":\n",
    "            modelpredDF = get_pred_knn(df.iloc[train_index],df.iloc[test_index],int(model_name[:-2]))\n",
    "        elif model_name==\"default\":\n",
    "            modelpredDF = get_pred_default(df.iloc[train_index],df.iloc[test_index])\n",
    "        modelpredDF['Fold']=count\n",
    "        count+=1\n",
    "        predDF = predDF.append(modelpredDF)\n",
    "    return predDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnsToKeep=[]\n",
    "# for i in trainingDF.columns:\n",
    "#     if any(char.isdigit() for char in i):\n",
    "#         continue\n",
    "#     else:\n",
    "#         columnsToKeep.append(i)\n",
    "# trainingDF = trainingDF.loc[:,columnsToKeep]\n",
    "# predDF = do_cv_class(trainingDF,10,'logreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predDF['Accuracy'] = predDF.apply(lambda r: 1 if r['Observed']==r['Prediction'] else 0,axis=1)\n",
    "# np.sum(predDF['Accuracy'])/float(len(predDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(confusion_matrix(predDF['Prediction'],predDF['Observed'],labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predDF['Prediction'] = predDF['Prediction'].astype(str).astype(int)\n",
    "# predDF['Observed'] = predDF['Observed'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagOfWordsResults(dateRange, nodeMinimum,nodeMaximum):\n",
    "    trainingDF = makeCorpusDataFrame(dateRange,nodeMinimum,nodeMaximum)\n",
    "    columnsToKeep=[]\n",
    "    for i in trainingDF.columns:\n",
    "        if any(char.isdigit() for char in i):\n",
    "            continue\n",
    "        else:\n",
    "            columnsToKeep.append(i)\n",
    "    trainingDF = trainingDF.loc[:,columnsToKeep]\n",
    "    predDF = do_cv_class(trainingDF,10,'logreg')\n",
    "    predDF['Prediction'] = predDF['Prediction'].astype(str).astype(int)\n",
    "    predDF['Observed'] = predDF['Observed'].astype(str).astype(int)\n",
    "    predDF['Accuracy'] = predDF.apply(lambda r: 1 if r['Observed']==r['Prediction'] else 0,axis=1)\n",
    "    print(np.sum(predDF['Accuracy'])/float(len(predDF)))\n",
    "    cf = confusion_matrix(predDF['Prediction'],predDF['Observed'],labels=[0,1])\n",
    "    return (cf[0][0],cf[0][1],cf[1][0],cf[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllPredDF = pd.DataFrame(columns=['Observed','Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_csv(\"nodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = nodes.loc[:,['Node Number','Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr2=[]\n",
    "tpr2=[]\n",
    "for i in range(len(answerResults)):\n",
    "    try:\n",
    "        fpr.append(answerResults[i][1])\n",
    "        tpr.append(answerResults[i][0])\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:20.585316\n",
      "0.9973313810693368\n"
     ]
    }
   ],
   "source": [
    "results = bagOfWordsResults(\"2018-02-04:2018-02-06\",25,66)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
